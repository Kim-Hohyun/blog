{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1199,
     "status": "ok",
     "timestamp": 1593102886282,
     "user": {
      "displayName": "Hohyun Kim",
      "photoUrl": "",
      "userId": "08560091150428894976"
     },
     "user_tz": -540
    },
    "id": "49iXKeWEPvnl"
   },
   "outputs": [],
   "source": [
    "def get_data(file_path):\n",
    "    questions, answers = [], []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            idx = line.find('_')\n",
    "            questions.append(line[:idx].strip())\n",
    "            answers.append(line[idx:-1].strip())\n",
    "    return questions, answers\n",
    "\n",
    "# 더하기 문제 데이터를 가져옵니다.\n",
    "# 어떤 데이터인지 직접 확인해보세요.\n",
    "file_path = './data/addition.txt'\n",
    "X_data, y_data = get_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3784,
     "status": "ok",
     "timestamp": 1593102893538,
     "user": {
      "displayName": "Hohyun Kim",
      "photoUrl": "",
      "userId": "08560091150428894976"
     },
     "user_tz": -540
    },
    "id": "S_emrZC8UXYG"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 각 문자를 토큰으로 나눠주고 패딩 처리를 합니다.\n",
    "tokenizer = Tokenizer(char_level=True, filters='')\n",
    "tokenizer.fit_on_texts(X_data)\n",
    "tokenizer.fit_on_texts(y_data)\n",
    "\n",
    "X_sequence = tokenizer.texts_to_sequences(X_data)\n",
    "y_sequence = tokenizer.texts_to_sequences(y_data)\n",
    "\n",
    "X_padded = pad_sequences(X_sequence)\n",
    "y_padded = pad_sequences(y_sequence, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1572,
     "status": "ok",
     "timestamp": 1593102896156,
     "user": {
      "displayName": "Hohyun Kim",
      "photoUrl": "",
      "userId": "08560091150428894976"
     },
     "user_tz": -540
    },
    "id": "b1K0NU5pPvnt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1766,
     "status": "ok",
     "timestamp": 1593102921603,
     "user": {
      "displayName": "Hohyun Kim",
      "photoUrl": "",
      "userId": "08560091150428894976"
     },
     "user_tz": -540
    },
    "id": "zKTM6yggUeDr"
   },
   "outputs": [],
   "source": [
    "embedding_size = 16\n",
    "hidden_size = 256\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "\n",
    "# 임베딩 레이어: 인코더와 디코더가 공유합니다.\n",
    "emb_layer = keras.layers.Embedding(vocab_size, embedding_size)\n",
    "\n",
    "# 인코더 정의\n",
    "# 1: 인풋 문자열이 임베딩 레이어를 통과합니다.\n",
    "# 2: 임베딩 레이어를 통과한 문자열 벡터들이 GRU 층을 통과합니다.\n",
    "# 3: GRU 층은 인풋 문자열들을 하나의 벡터로 변환합니다. 그 벡터를 아웃풋으로 내보냅니다.encoder_input = keras.layers.Input(shape=(None,))\n",
    "encoder_input = keras.layers.Input(shape=(None,))\n",
    "x = emb_layer(encoder_input)\n",
    "encoder_state = keras.layers.GRU(hidden_size)(x)\n",
    "encoder = keras.Model(encoder_input, encoder_state)\n",
    "\n",
    "# 디코더 정의\n",
    "# 1: 디코더에는 두 개의 인풋이 있습니다. \n",
    "  # 인풋1: 인코더에서 넘겨준 은닉 벡터를 받습니다.\n",
    "  # 인풋2: 디코딩 시작을 알리는 문자열(_)과 다른 문자열들을 받습니다.\n",
    "  #        다른 문자열이란 (추론단계에서는) 이전 타임스탭에서 확률이 높다고 예측한 문자열입니다.\n",
    "# 2: 임베딩 레이어는 인코더와 공유합니다. (선택사항입니다.)\n",
    "# 3: GRU 층을 통과한 뒤, 덴스 층에서 다음에 올 문자열의 확률 값을 구합니다.\n",
    "decoder_state_input = keras.layers.Input(shape=(None,))  \n",
    "decoder_input = keras.layers.Input(shape=(None,)) \n",
    "x = emb_layer(decoder_input)\n",
    "x, decoder_state = keras.layers.GRU(hidden_size, return_state=True, return_sequences=True)(x, decoder_state_input)\n",
    "decoder_output = keras.layers.Dense(vocab_size, activation='softmax')(x)\n",
    "decoder = keras.Model([decoder_state_input, decoder_input], [decoder_state, decoder_output])\n",
    "\n",
    "# 인코더-디코더 모델\n",
    "# 인코더와 디코더를 연결합니다.\n",
    "decoder_state, model_output = decoder([encoder_state, decoder_input])\n",
    "model = keras.Model([encoder_input, decoder_input], model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39877,
     "status": "ok",
     "timestamp": 1593102963827,
     "user": {
      "displayName": "Hohyun Kim",
      "photoUrl": "",
      "userId": "08560091150428894976"
     },
     "user_tz": -540
    },
    "id": "g-VQ7LOaPvn0",
    "outputId": "0c47f8c6-4ce0-4ae0-e940-494be6167b3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "293/293 [==============================] - 4s 12ms/step - loss: 1.8218 - accuracy: 0.3354 - val_loss: 1.7184 - val_accuracy: 0.3453\n",
      "Epoch 2/10\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 1.6235 - accuracy: 0.3801 - val_loss: 1.4372 - val_accuracy: 0.4653\n",
      "Epoch 3/10\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 1.3275 - accuracy: 0.4940 - val_loss: 1.2768 - val_accuracy: 0.5046\n",
      "Epoch 4/10\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 1.1957 - accuracy: 0.5468 - val_loss: 1.1469 - val_accuracy: 0.5650\n",
      "Epoch 5/10\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.0816 - accuracy: 0.5891 - val_loss: 0.9780 - val_accuracy: 0.6293\n",
      "Epoch 6/10\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8470 - accuracy: 0.6813 - val_loss: 0.7298 - val_accuracy: 0.7250\n",
      "Epoch 7/10\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.6725 - accuracy: 0.7442 - val_loss: 0.6208 - val_accuracy: 0.7621\n",
      "Epoch 8/10\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.5839 - accuracy: 0.7721 - val_loss: 0.5627 - val_accuracy: 0.7764\n",
      "Epoch 9/10\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.5351 - accuracy: 0.7860 - val_loss: 0.4969 - val_accuracy: 0.7982\n",
      "Epoch 10/10\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.4786 - accuracy: 0.8075 - val_loss: 0.4614 - val_accuracy: 0.8128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f98dc715eb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit([X_train, y_train[:, :-1]], y_train[:, 1:], \n",
    "          epochs=10, batch_size=128, \n",
    "         validation_data=([X_test, y_test[:, :-1]], y_test[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1195,
     "status": "ok",
     "timestamp": 1593103183294,
     "user": {
      "displayName": "Hohyun Kim",
      "photoUrl": "",
      "userId": "08560091150428894976"
     },
     "user_tz": -540
    },
    "id": "DJIt7ZHlPvn6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 이제 테스트 세트 전체에 대해 모델이 문제를 잘 맞히는지 보겠습니다.\n",
    "# 인코더에는 문제를 인풋으로 넣습니다.\n",
    "# 디코더에는 시작 문자인 '_'를 넣습니다.\n",
    "# 디코더에서 다음에 올 문자의 확률을 구합니다. 가장 높은 확률의 문자를 선택합니다.\n",
    "# 다음 GRU 셀은 이전의 은닉 벡터(hidden_state)와 이전 타임스탭에서 선택된 문자가 입력됩니다.\n",
    "hidden_state = encoder(X_test)\n",
    "pred = []\n",
    "start_id = np.array(tokenizer.texts_to_sequences(\"_\"))\n",
    "next_input = start_id.repeat(len(X_test), axis=0)\n",
    "for _ in range(5):\n",
    "    hidden_state, out = decoder([hidden_state, next_input])\n",
    "    out = out.numpy().argmax(-1)\n",
    "    pred.append(out)\n",
    "    next_input = out\n",
    "    \n",
    "X = tokenizer.sequences_to_texts(X_test)\n",
    "y = tokenizer.sequences_to_texts(np.hstack(pred)) # hstack: pred 안에 있는 넘파이를 가로로(horizontally) 이어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1714,
     "status": "ok",
     "timestamp": 1593103186728,
     "user": {
      "displayName": "Hohyun Kim",
      "photoUrl": "",
      "userId": "08560091150428894976"
     },
     "user_tz": -540
    },
    "id": "UmrCjdJ-Pvn9",
    "outputId": "6494338d-6008-4087-ef0e-4e23b10b295e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제: 104+822\n",
      "정답: 926\n",
      "제출: 927\n",
      "-----\n",
      "문제: 790+986\n",
      "정답: 1776\n",
      "제출: 1775\n",
      "-----\n",
      "문제: 633+61\n",
      "정답: 694\n",
      "제출: 693\n",
      "-----\n",
      "문제: 91+904\n",
      "정답: 995\n",
      "제출: 995\n",
      "-----\n",
      "문제: 360+9\n",
      "정답: 369\n",
      "제출: 370\n",
      "-----\n",
      "문제: 10+626\n",
      "정답: 636\n",
      "제출: 637\n",
      "-----\n",
      "문제: 722+585\n",
      "정답: 1307\n",
      "제출: 1304\n",
      "-----\n",
      "문제: 60+615\n",
      "정답: 675\n",
      "제출: 677\n",
      "-----\n",
      "문제: 841+69\n",
      "정답: 910\n",
      "제출: 908\n",
      "-----\n",
      "문제: 44+538\n",
      "정답: 582\n",
      "제출: 582\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 문제(인코더의 입력값), 정답, 그리고 모델이 추론한 값을 출력합니다.\n",
    "n_show = 10\n",
    "\n",
    "for i in range(n_show):\n",
    "    print('문제:', X[i].replace(' ', ''))\n",
    "    print('정답:', sum([int(n) for n in X[i].replace(' ', '').split('+')]))\n",
    "    print('제출:', y[i].replace(' ', ''))\n",
    "    print('-'*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilA_2nF0PvoC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "(3.4) Seq2Seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
