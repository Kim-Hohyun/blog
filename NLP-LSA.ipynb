{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잠재 의미 분석(Latent Semantic Analysis, LSA)을 통해 단어 벡터화 기법을 실습하고 단어 간 유사도를 구해볼 것입니다. 여기서의 코드 예제 및 설명은 《밑바닥부터 시작하는 딥러닝 2》를 참고했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTB 데이터 불러오기\n",
    "\n",
    "**펜 트리뱅크**(Penn Treebank, PTB) 데이터셋. word2vec 발명자인 토마스 미콜로프(Tomas Mikolov) 웹 페이지에서 받을 수 있습니다. 원래의 PTB 문장에 몇 가지 전처리가 되어있습니다. 희소한 단어는 `<unk>`로 치환되어 있다던가, 구체적인 숫자는 `N`으로 대체되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'ptb.train.txt' in os.listdir():\n",
    "    with open(\"ptb.train.txt\", 'r') as f:\n",
    "        text = f.read()        \n",
    "else:\n",
    "    from urllib.request import urlopen\n",
    "    url = 'https://raw.githubusercontent.com/tomsercu/lstm/master/data/ptb.train.txt'\n",
    "    html = urlopen(url)\n",
    "    text = html.read().decode()\n",
    "\n",
    "    with open(\"ptb.train.txt\", 'w') as f:\n",
    "        f.write(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계기반 벡터화\n",
    "\n",
    "동시발행 행렬을 만들고, PPMI 행렬로 변환한 다음, 안정성을 높이기 위해 SVD를 이용해 차원을 감소시켜 각 단어의 분산 표현을 만들어냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 전처리\n",
    "def preprocess(text):\n",
    "    \n",
    "    words = text.replace('\\n', '<eos>').strip().split()\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "    \n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    \n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n",
    "# 동시발생 행렬 만들기\n",
    "def create_co_matrix(corpus, vocab_size, window_size):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size))\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size+1):\n",
    "            left_idx = idx-i\n",
    "            right_idx = idx+i\n",
    "            \n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "                \n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "    return co_matrix\n",
    "\n",
    "# 양의 상호정보량 구하기\n",
    "def ppmi(C, eps=1e-8):\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0, keepdims=True)\n",
    "    pmi = np.log2(C * N / np.dot(S.T, S) + eps)\n",
    "    ppmi = np.maximum(pmi, 0)\n",
    "    return ppmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 수 계산 ...\n",
      "PPMI 계산 ...\n",
      "SVD 계산 ...\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(\"동시발생 수 계산 ...\")\n",
    "vocab_size = len(word_to_id)\n",
    "co_matrix = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print(\"PPMI 계산 ...\")\n",
    "W = ppmi(co_matrix)\n",
    "\n",
    "print(\"SVD 계산 ...\")\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=wordvec_size, algorithm='randomized', n_iter=5)\n",
    "word_vecs = svd.fit_transform(W) \n",
    "\n",
    "# 동일한 다른 방법\n",
    "# from sklearn.utils.extmath import randomized_svd\n",
    "# word_vecs, _, _ = randomized_svd(W, n_components=wordvec_size, n_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가\n",
    "\n",
    "특정 단어를 넣었을 때 유사한 단어를 가려낼 수 있는지, 그리고 단어 간 비유적 관계를 찾아낼 수 있는지를 볼 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 비슷한 단어 출력\n",
    "def most_similar(query, word_to_id, id_to_word, similarity_matirx, top=5):\n",
    "    if query not in word_to_id:\n",
    "        print('%s(을)를 찾을 수 없습니다.' % query)\n",
    "        return\n",
    "    \n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    similarity = similarity_matirx[query_id]\n",
    "    \n",
    "    # 코사인 유사도 기준으로 내림차순으로 출력\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "        \n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return\n",
    "\n",
    "\n",
    "def analogy(a, b, c, word_to_id, id_to_word, word_vecs, top=5):\n",
    "    for word in (a, b, c):\n",
    "        if word not in word_to_id:\n",
    "            print('%s(을)를 찾을 수 없습니다.' % word)\n",
    "            return\n",
    "\n",
    "    print('\\n[analogy] ' + a + ':' + b + ' = ' + c + ':?')\n",
    "    a_vec, b_vec, c_vec = word_vecs[word_to_id[a]], word_vecs[word_to_id[b]], word_vecs[word_to_id[c]]\n",
    "    query_vec = b_vec - a_vec + c_vec\n",
    "    word_vecs_norm = word_vecs / np.linalg.norm(word_vecs, axis=1, keepdims=True)\n",
    "    similarity = np.dot(word_vecs_norm, query_vec)\n",
    "\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] in (a, b, c):\n",
    "            continue\n",
    "        print(' {0}: {1}'.format(id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " i: 0.8306300170286577\n",
      " we: 0.8035908083942216\n",
      " do: 0.7708317864744261\n",
      " anybody: 0.7187499925464061\n",
      " me: 0.714916179863626\n",
      "\n",
      "[query] year\n",
      " month: 0.805700784664732\n",
      " earlier: 0.7794736001090208\n",
      " last: 0.764942901327093\n",
      " quarter: 0.7595937077934993\n",
      " next: 0.7352714292723379\n",
      "\n",
      "[query] car\n",
      " auto: 0.7221239761747404\n",
      " luxury: 0.6844566161549585\n",
      " vehicle: 0.6641306110764477\n",
      " domestic: 0.6436364956725468\n",
      " cars: 0.6325514759427554\n",
      "\n",
      "[query] toyota\n",
      " motor: 0.765696078978967\n",
      " nissan: 0.7279285766332921\n",
      " honda: 0.7101727101809763\n",
      " lexus: 0.6941262574287386\n",
      " mazda: 0.688327613804317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matirx = cosine_similarity(word_vecs)\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, similarity_matirx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[analogy] king:man = queen:?\n",
      " woman: 13.991380407599534\n",
      " worker: 12.462211530638415\n",
      " boy: 11.3781268479203\n",
      " himself: 11.107136042208209\n",
      " whom: 10.898577075485491\n",
      "\n",
      "[analogy] take:took = go:?\n",
      " went: 21.543986158254434\n",
      " goes: 19.119449644036862\n",
      " turns: 18.18632683900878\n",
      " ran: 17.23701191060183\n",
      " moved: 17.007751976888613\n",
      "\n",
      "[analogy] car:cars = child:?\n",
      " roads: 11.46565419105771\n",
      " quantity: 11.462979319796093\n",
      " disabled: 11.333230016723235\n",
      " hats: 11.14799930309691\n",
      " repairs: 11.061422359090107\n",
      "\n",
      "[analogy] good:better = bad:?\n",
      " worse: 14.262228925724756\n",
      " significantly: 12.660040328256034\n",
      " bigger: 12.586679909336176\n",
      " faster: 12.353641162541454\n",
      " anyway: 12.265623801513282\n"
     ]
    }
   ],
   "source": [
    "analogy('king', 'man', 'queen',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('take', 'took', 'go',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('car', 'cars', 'child',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('good', 'better', 'bad',  word_to_id, id_to_word, word_vecs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
