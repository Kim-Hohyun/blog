{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"추천 시스템.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XD8V-oUrTTL4","colab_type":"text"},"source":["이 글은 pytorch를 이용해서 추천 시스템을 만드는 방법을 소개하고 있습니다. \n","코드는 Jpub 출판 '파이토치 첫걸음'을 참고했습니다.\n","\n","참고로 아래 코드는 구글 colab에서 작성되었습니다.코드 중간에 나오는 path 등은 코랩 기준입니다."]},{"cell_type":"markdown","metadata":{"id":"1K45uVW2keMK","colab_type":"text"},"source":["# 데이터 다운로드"]},{"cell_type":"markdown","metadata":{"id":"eB_5RMcLUIdy","colab_type":"text"},"source":["추천 시스템에 사용되는 대표적인 데이터 셋인 무비렌즈 데이터를 이용할 것입니다.\n","\n","데이터에 대한 설명은 https://grouplens.org/datasets/movielens/ 에서 보실 수 있습니다.\n","\n","데이터는 리눅스라면 아래처럼 wget을 이용해 가져올 수도 있습니다.\n","\n","아니면 http://files.grouplens.org/datasets/movielens/ml-20m.zip 에 들어가면 압축파일이 다운받아집니다."]},{"cell_type":"code","metadata":{"id":"YpPrxE4Of2mG","colab_type":"code","outputId":"3ac62456-297d-4c9c-dc16-9715bdda303d","executionInfo":{"status":"ok","timestamp":1568087230369,"user_tz":-540,"elapsed":17470,"user":{"displayName":"김호현","photoUrl":"","userId":"14192226292936313885"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["!wget http://files.grouplens.org/datasets/movielens/ml-20m.zip\n","!unzip ml-20m.zip"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2019-09-10 03:46:57--  http://files.grouplens.org/datasets/movielens/ml-20m.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 198702078 (189M) [application/zip]\n","Saving to: ‘ml-20m.zip’\n","\n","ml-20m.zip          100%[===================>] 189.50M  47.8MB/s    in 4.4s    \n","\n","2019-09-10 03:47:01 (43.1 MB/s) - ‘ml-20m.zip’ saved [198702078/198702078]\n","\n","Archive:  ml-20m.zip\n","   creating: ml-20m/\n","  inflating: ml-20m/genome-scores.csv  \n","  inflating: ml-20m/genome-tags.csv  \n","  inflating: ml-20m/links.csv        \n","  inflating: ml-20m/movies.csv       \n","  inflating: ml-20m/ratings.csv      \n","  inflating: ml-20m/README.txt       \n","  inflating: ml-20m/tags.csv         \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Par8JTNqkhOH","colab_type":"text"},"source":["# 데이터 임포트"]},{"cell_type":"markdown","metadata":{"id":"SOyBXYFoVsf6","colab_type":"text"},"source":["압축 파일을 열면 ratings.csv란 파일이 있습니다. 이 파일 안에 영화에 대한 유저별 평가 데이터가 들어있습니다."]},{"cell_type":"code","metadata":{"id":"q7RDg_5okRYh","colab_type":"code","outputId":"03e7054c-6d3c-4202-d00b-68911b77091f","executionInfo":{"status":"ok","timestamp":1568087239964,"user_tz":-540,"elapsed":27059,"user":{"displayName":"김호현","photoUrl":"","userId":"14192226292936313885"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["import pandas as pd\n","\n","df = pd.read_csv(\"/content/ml-20m/ratings.csv\")\n","df.head()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userId</th>\n","      <th>movieId</th>\n","      <th>rating</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3.5</td>\n","      <td>1112486027</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>29</td>\n","      <td>3.5</td>\n","      <td>1112484676</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>32</td>\n","      <td>3.5</td>\n","      <td>1112484819</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>47</td>\n","      <td>3.5</td>\n","      <td>1112484727</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>50</td>\n","      <td>3.5</td>\n","      <td>1112484580</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   userId  movieId  rating   timestamp\n","0       1        2     3.5  1112486027\n","1       1       29     3.5  1112484676\n","2       1       32     3.5  1112484819\n","3       1       47     3.5  1112484727\n","4       1       50     3.5  1112484580"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"7ISBzqHdV8TC","colab_type":"text"},"source":["데이터는 유저ID, 영화ID, 평점, 평가한 시간입니다.\n","평가 시간은 1970년 1월 1일 기준으로 경과한 초 단위 시간을 나타냅니다. \n","이 튜토리얼에서는 시간 데이터는 이용하지 않을 것입니다."]},{"cell_type":"code","metadata":{"id":"US-jY25ilDsz","colab_type":"code","outputId":"1efa2cb8-ff88-4e4d-9429-12c8ce1d2f0c","executionInfo":{"status":"ok","timestamp":1568087290338,"user_tz":-540,"elapsed":732,"user":{"displayName":"김호현","photoUrl":"","userId":"14192226292936313885"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["# 200만 건이 넘는 데이터입니다.\n","df.shape"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20000263, 4)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"4rMpK_R-lP3G","colab_type":"code","outputId":"da5c8de5-5769-40ea-9f1d-3f5200885956","executionInfo":{"status":"ok","timestamp":1568087293558,"user_tz":-540,"elapsed":729,"user":{"displayName":"김호현","photoUrl":"","userId":"14192226292936313885"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["# 평가 점수는 0.5점 단위로 0.5에서 5점까지로 구성되어 있습니다.\n","sorted(df['rating'].unique())"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"Fan4vzQcX5VD","colab_type":"text"},"source":["지금 만들려고 하는 것은 추천 시스템입니다. 말하자면 A유저가 좋아할 만한 영화를 추천하고자 하는 것입니다. 그리고 '좋아한다'의 기준이 평점이라 한다면 문제를 다음과 같이 재정의할 수 있을 것입니다.\n","\n","**유저ID와 영화ID를 입력으로 받아서 해당 영화에 대한 평점을 예측하는 문제**\n","\n","그러므로 평점이 y(레이블)에 해당하고, 유저ID와 영화ID가 x1, x2가 됩니다.\n","\n","사이킷런의 train_test_split 함수를 통해 레이블과 테스트 데이터를 분리하겠습니다.\n"]},{"cell_type":"code","metadata":{"id":"YwX_7AKbkjI9","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","data = df[['userId', 'movieId']].values\n","target = df['rating'].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.1, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUz2qqtK3LoR","colab_type":"code","outputId":"0cf9c6c3-cba8-4202-e20b-f3a9927ec476","executionInfo":{"status":"ok","timestamp":1568087306912,"user_tz":-540,"elapsed":2678,"user":{"displayName":"김호현","photoUrl":"","userId":"14192226292936313885"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["# 훈련 데이터에 약 180만 개의 데이터가 할달되었습니다.\n","X_train.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(18000236, 2)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"uNZY5r5abFwQ","colab_type":"text"},"source":["이제 데이터를 파이토치 모델에 넣을 수 있는 형태로 바꾸는 과정입니다.\n","\n","파이토치 텐서 객체로 변환해주고, X값과 y값을 묶어서 데이터셋 객체로 만들어줍니다.\n","\n","저는 무비렌즈 데이터가 크기 때문에, 훈련 데이터를 반으로 쪼개서 훈련 세트를 두 개 만들어주었습니다."]},{"cell_type":"code","metadata":{"id":"U7jaWWYjlsxY","colab_type":"code","colab":{}},"source":["from torch.utils.data import DataLoader, TensorDataset\n","import torch\n","from torch import nn, optim\n","\n","train_dataset1 = TensorDataset(torch.tensor(X_train[:9000000], dtype=torch.int64), \n","                               torch.tensor(y_train[:9000000], dtype=torch.float32))\n","train_dataset2 = TensorDataset(torch.tensor(X_train[9000000:], dtype=torch.int64), \n","                               torch.tensor(y_train[9000000:], dtype=torch.float32))\n","\n","train_loader1 = DataLoader(train_dataset1, batch_size=1024, shuffle=True)\n","train_loader2 = DataLoader(train_dataset2, batch_size=1024, shuffle=True)\n","\n","test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.int64), \n","                             torch.tensor(y_test, dtype=torch.float32))\n","test_loader = DataLoader(test_dataset, batch_size=1024)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-Y9L9eBlxj9","colab_type":"text"},"source":["# 모델 만들기"]},{"cell_type":"markdown","metadata":{"id":"blJ0b6q6cIEZ","colab_type":"text"},"source":["여기서는 모델을 두 개 만들어볼 것입니다.\n","\n","하나는 유저ID와 무비ID를 받아서 영화에 대한 평점을 예측하는 모델이고,다른 하나는 영화 장르 정보까지 이용해서 평점을 예측하는 모델입니다. 이용하는 정보만 추가되었을 뿐 같은 모델입니다.\n","\n","방법은 다음과 같습니다.\n","\n","1. 유저ID별로 길이가 user_k인 벡터를 하나씩 부여합니다.\n","\n","2. 영화ID도 마찬가지로 길이가 item_k인 벡터를 부여합니다.\n","\n","3. 유저ID 벡터와 영화ID 벡터를 합쳐서 길이가 user_k + item_k인 벡터를 만듭니다.\n","\n","4. 그렇게 만들어진 벡터를 은닉층이 하나인 완전연결 층에 넣습니다.\n","\n","5. 마지막 층의 활성화함수는 시그모이드를 사용했습니다. 그러나 영화 평점은 5점까지므로 곱하기 5를 해줍니다.\n","\n","여기서 1번 단계 구현을 위해 사용하는 레이어가 임베딩 레이어입니다. 임베딩 레이어는 인덱스(정수)를 받아서 원하는 길이만큼의 벡터를 반환해줍니다.\n","\n","모델에 인풋으로 넣어주는 것은 크기가 (batch size, 2)인 텐서입니다. 텐서의 첫 번째 열은 유저ID고 두 번째 열은 영화ID입니다.\n","\n","인풋으로 들어간 텐서는 크기가 (batch size,)인 텐서로 쪼개집니다. 두 개의 텐서는 각각 유저ID와 영화ID를 표현합니다.\n","\n","쪼개진 텐서를 이제 각각 벡터로 변환해줘야 합니다. 각각 유저ID를 벡터로 변환해주는 유저ID 임베딩 레이어와 영화ID를 벡터로 변환해주는 영화ID 임베딩 레이어로 집어넣어줍니다.임베딩 레이어를 통과하면 각각 (batch size, user_k), (batch size, item_k) 크기의 텐서가 만들어지고, 이를 하나로 합쳐서 (batch size, user_k + item_k) 크기의 텐서로 만들어줍니다.\n","\n","이제 인풋 크기가 user_k+item_k이고 아웃풋이 1인 완전연결 층에 넣어주어 모델을 학습시키면 됩니다.그러면 완전연결 층의 파라미터뿐만 아니라 임베딩 층의 파라미터까지 학습이 이루어져서, 각각 유저와 각각의 영화에 해당하는 벡터 표현을 구할 수 있습니다. "]},{"cell_type":"code","metadata":{"id":"raaQRQwHgQTm","colab_type":"code","colab":{}},"source":["# 사용할 모델\n","\n","class NeuralMatrixFactorization(nn.Module):\n","  def __init__(self, max_user, max_item, user_k=10, item_k=10, hidden_dim=50):\n","    super().__init__()\n","    self.user_emb = nn.Embedding(max_user, user_k, 0)\n","    self.item_emb = nn.Embedding(max_item, item_k, 0)\n","    self.mlp = nn.Sequential(\n","        nn.Linear(user_k + item_k, hidden_dim),\n","        nn.ReLU(),\n","        nn.BatchNorm1d(hidden_dim),\n","        nn.Linear(hidden_dim, hidden_dim),\n","        nn.ReLU(),\n","        nn.BatchNorm1d(hidden_dim),\n","        nn.Linear(hidden_dim, 1)\n","    )\n","  def forward(self, x):\n","    user_idx = x[:, 0]\n","    item_idx = x[:, 1]\n","    user_feature = self.user_emb(user_idx) # (batch_size, user_k)\n","    item_feature = self.item_emb(item_idx) # (batch_size, item_k)\n","    \n","    out = torch.cat([user_feature, item_feature], 1) # (batch_size, user_k+item_k)\n","    out = self.mlp(out)  # (batch_size, 1)\n","    out = torch.sigmoid(out) * 5\n","    return out.squeeze()   # (batch_size,)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H23QysCFo3_i","colab_type":"code","colab":{}},"source":["# 평가함수 작성\n","\n","def eval_net(net, loader, score_fn=nn.functional.l1_loss, device='cpu'): # 훈련은 MSE로 하되, 평가는 해석하기가 쉬운 l1_loss를 사용했습니다.\n","  ys = []\n","  y_preds = []\n","  for x, y in loader:\n","    x = x.to(device)\n","    ys.append(y)\n","    with torch.no_grad():\n","      y_pred = net(x).cpu()\n","    y_preds.append(y_pred)\n","  score = score_fn(torch.cat(ys).squeeze(), torch.cat(y_preds))\n","  return score.item()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WgTOLcooqNM6","colab_type":"code","colab":{}},"source":["# 훈련 부분 작성하기\n","from statistics import mean\n","\n","def train_net(net, loss_fn, optimizer, loader, device='cpu'):\n","  losses = []\n","  for x, y in loader:\n","    x = x.to(device)\n","    y = y.to(device)\n","    out = net(x)\n","    loss = loss_fn(out, y)\n","    net.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    losses.append(loss.item())\n","  return mean(losses)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Eq7tBO03lgs","colab_type":"code","outputId":"d997816c-6863-4e9b-ba31-75b60f0420f8","executionInfo":{"status":"ok","timestamp":1568097993062,"user_tz":-540,"elapsed":474521,"user":{"displayName":"김호현","photoUrl":"","userId":"14192226292936313885"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["# 훈련하기\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","max_user, max_item = data.max(0) # 유저ID와 영화ID는 1부터 시작해서 1씩 증가합니다. 그러므로 max를 취해주면 유저ID와 영화ID 개수가 반환됩니다.\n","max_user = int(max_user) + 1     # 새로운 유저나 영화가 인풋으로 들어올 것에 대비해 +1을 해줍니다.\n","max_item = int(max_item) + 1\n","\n","net = NeuralMatrixFactorization(max_user, max_item)\n","net.cuda()\n","optimizer = optim.Adam(net.parameters(), lr=0.01) # 데이터가 크기 때문에 넓은 공간을 탐색하기 쉽도록 학습률을 크게 합니다.\n","loss_fn = nn.MSELoss()\n","\n","\n","for epoch in range(3): # 시간이 오래 걸려서 에폭 3으로 했습니다.\n","  \n","  net.train()\n","  loss = train_net(net, loss_fn, optimizer, train_loader1, device=device)\n","  net.eval()\n","  test_score = eval_net(net, test_loader, device=device)\n","  print(epoch, loss, test_score)\n","  \n","  net.train()\n","  loss = train_net(net, loss_fn, optimizer, train_loader2, device=device)\n","  net.eval()\n","  test_score = eval_net(net, test_loader, device=device)\n","  print(epoch, loss, test_score)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["0 0.785351644861549 0.6597837805747986\n","0 0.7191154012772275 0.640923023223877\n","1 0.6957194821690807 0.6368798613548279\n","1 0.6823071704111544 0.6314395666122437\n","2 0.673727889462407 0.6285171508789062\n","2 0.6675265018375796 0.6270928382873535\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7JgRPVATxYqE","colab_type":"text"},"source":["# 장르 정보 이용"]},{"cell_type":"markdown","metadata":{"id":"SDeBa5di6Yhd","colab_type":"text"},"source":["영화의 장르 정보는 movies.csv 파일에 별도로 저장되어 있습니다."]},{"cell_type":"code","metadata":{"id":"P2fsw6aFqLgp","colab_type":"code","outputId":"5e442bf2-e119-4fc6-efd6-871fb9c0d6dd","executionInfo":{"status":"ok","timestamp":1568088500319,"user_tz":-540,"elapsed":712,"user":{"displayName":"김호현","photoUrl":"","userId":"14192226292936313885"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["genre_data = pd.read_csv(\"/content/ml-20m/movies.csv\")\n","genre_data.head()  "],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movieId</th>\n","      <th>title</th>\n","      <th>genres</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Toy Story (1995)</td>\n","      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Jumanji (1995)</td>\n","      <td>Adventure|Children|Fantasy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Grumpier Old Men (1995)</td>\n","      <td>Comedy|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Waiting to Exhale (1995)</td>\n","      <td>Comedy|Drama|Romance</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Father of the Bride Part II (1995)</td>\n","      <td>Comedy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   movieId  ...                                       genres\n","0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n","1        2  ...                   Adventure|Children|Fantasy\n","2        3  ...                               Comedy|Romance\n","3        4  ...                         Comedy|Drama|Romance\n","4        5  ...                                       Comedy\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"iKXCFJbL6eo7","colab_type":"text"},"source":["타이틀에 연도 정보까지 있네요. 저희는 장르 정보만 이용할 것입니다.\n","\n","하나의 영화가 여러 장르에 속할 경우 '|' 표시로 구분되고 있습니다. \n","\n","장르 정보를 이용하는 방식은 다음과 같습니다.\n","\n","이전에 저는 영화ID마다 하나의 벡터를 배정해주었습니다.\n","\n","이번에도 똑같이 영화ID마다 하나의 벡터를 배정해주되, 배정되는 벡터에서 일부 차원은 영화의 장르 정보를 담고 있도록 만드는 겁니다.\n","\n","이를 위해서 장르 정보만을 위한 임베딩 레이어를 따로 만들어 학습할 수도 있지만, 여기서는 속하는 장르의 차원은 값이 1이고 속하지 않는 장르 차원은 값이 0인 벡터로 장르 정보를 표현해주겠습니다.\n","\n","\n","이를 위해 사이킷런의 CountVectorizer 모듈을 이용하겠습니다. CountVectorizer는 전체 텍스트를 조사해 단어 사전을 구축한 뒤, 각각의 문서를 단어 출현 빈도 벡터로 변환해줍니다.\n","\n","예를 들어, 어떤 영화가 로멘스, 액션, 판타지에 속하고 코메디는 아니라면, [1, 1, 1, 0]으로 표현할 수 있을 것입니다. 이를 영화 임베딩 레이어를 통과한 벡터와 합치면 결국 장르 정보까지도 표현하는, 영화ID를 표현하는 벡터 더 큰 차원의 벡터 표현이 만들어지게 됩니다."]},{"cell_type":"code","metadata":{"id":"WQa0GKHe6rx8","colab_type":"code","outputId":"2f65e2bf-a343-41f7-a5f5-ae64416a9faf","executionInfo":{"status":"ok","timestamp":1568088501618,"user_tz":-540,"elapsed":782,"user":{"displayName":"김호현","photoUrl":"","userId":"14192226292936313885"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","movie_id = genre_data['movieId']\n","genres = genre_data['genres']\n","\n","count_vec = CountVectorizer()\n","count_vec.fit(genres)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n","                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n","                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n","                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n","                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n","                tokenizer=None, vocabulary=None)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"KzCwPjrY8KZW","colab_type":"text"},"source":["24개의 장르가 있는 것을 볼 수 있습니다."]},{"cell_type":"code","metadata":{"id":"5E18Yon97g6z","colab_type":"code","outputId":"08d5984c-2632-403f-9698-da054ba40b04","executionInfo":{"status":"ok","timestamp":1568088502645,"user_tz":-540,"elapsed":699,"user":{"displayName":"김호현","photoUrl":"","userId":"14192226292936313885"}},"colab":{"base_uri":"https://localhost:8080/","height":465}},"source":["count_vec.vocabulary_"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'action': 0,\n"," 'adventure': 1,\n"," 'animation': 2,\n"," 'children': 3,\n"," 'comedy': 4,\n"," 'crime': 5,\n"," 'documentary': 6,\n"," 'drama': 7,\n"," 'fantasy': 8,\n"," 'fi': 9,\n"," 'film': 10,\n"," 'genres': 11,\n"," 'horror': 12,\n"," 'imax': 13,\n"," 'listed': 14,\n"," 'musical': 15,\n"," 'mystery': 16,\n"," 'no': 17,\n"," 'noir': 18,\n"," 'romance': 19,\n"," 'sci': 20,\n"," 'thriller': 21,\n"," 'war': 22,\n"," 'western': 23}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"7uZSpPgV_sZl","colab_type":"text"},"source":["장르 정보를 텐서로 바꾸어줍니다. 그리고 영화ID를 넣으면 해당 영화의 장르 벡터가 반환되도록 사전을 만들어줍니다."]},{"cell_type":"code","metadata":{"id":"dPucNeim8Bfg","colab_type":"code","colab":{}},"source":["num_genres = len(count_vec.vocabulary_)\n","genre_vec = count_vec.transform(genres).toarray()\n","genre_vec = torch.tensor(genre_vec, dtype=torch.float32)\n","genre_dict = dict(zip(movie_id, genre_vec))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JjsBCTN7CtOi","colab_type":"text"},"source":["## 커스텀 데이터 로더 만들기"]},{"cell_type":"markdown","metadata":{"id":"JP73cGo7_76b","colab_type":"text"},"source":["모델은 두 가지 방식으로 구현이 가능합니다.\n","\n","하나는 유저ID와 영화ID를 넣으면 모델 내에서 각각의 ID에 해당하는 벡터 표현을 가져와 완전연결 층의 입력으로 전달해주는 것입니다.\n","\n","다른 하나는 모델 입력으로 (유저ID, 영화ID, 장르 정보)의 쌍을 넣는 것입니다. \n","\n","아래 코드는 후자를 선택했습니다. 모델에 입력으로 넣을 데이터에 장르 정보(해당 영화ID에 해당하는 장르 텐서)가 추가되었으니, 데이터 로더를 새롭게 구성해줍니다."]},{"cell_type":"code","metadata":{"id":"IMZXIHq48Yw2","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset\n","\n","class MovieLensDataset(Dataset):\n","  def __init__(self, x, y, genre_dict):\n","    assert len(x) == len(y)\n","    self.x = x\n","    self.y = y\n","    self.genre_dict = genre_dict\n","    \n","  def __len__(self):\n","    return len(self.x)\n","  \n","  def __getitem__(self, idx):\n","    x = self.x[idx]\n","    y = self.y[idx]\n","    g = self.genre_dict.get(x[1].item()) # 새로운 데이터에 대해 실험할 때는 보지 못한 유저ID나 영화ID가 나올 것에 대비해야 합니다. \n","                                         # 여기서는 이 부분을 처리하지 않았습니다.\n","    return x, y, g # 유저ID, 영화ID, 장르 텐서"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qxI42i-PA0Pd","colab_type":"code","colab":{}},"source":["train_dataset1 = MovieLensDataset(\n","    torch.tensor(X_train[:9000000], dtype=torch.int64),\n","    torch.tensor(y_train[:9000000], dtype=torch.float32),\n","    genre_dict\n",")\n","train_dataset2 = MovieLensDataset(\n","    torch.tensor(X_train[9000000:], dtype=torch.int64),\n","    torch.tensor(y_train[9000000:], dtype=torch.float32),\n","    genre_dict\n",")\n","test_dataset = MovieLensDataset(\n","    torch.tensor(X_test, dtype=torch.int64),\n","    torch.tensor(y_test, dtype=torch.float32),\n","    genre_dict\n",")\n","\n","train_loader1 = DataLoader(train_dataset1, batch_size=1024, shuffle=True)\n","train_loader2 = DataLoader(train_dataset2, batch_size=1024, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=1024)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QpjGoow4CwML","colab_type":"text"},"source":["## 모델 작성"]},{"cell_type":"markdown","metadata":{"id":"EAJ_1oKyBRhn","colab_type":"text"},"source":["모델은 완전연결 층의 인풋 크기가 장르 개수만큼 늘어난 것을 제외하고는 똑같습니다."]},{"cell_type":"code","metadata":{"id":"KGINZlyGCkam","colab_type":"code","colab":{}},"source":["class NeuralMatrixFactorization2(nn.Module):\n","  def __init__(self, max_user, max_item, num_genres, user_k=10, item_k=10, hidden_dim=50):\n","    super().__init__()\n","    self.user_emb = nn.Embedding(max_user, user_k, 0)\n","    self.item_emb = nn.Embedding(max_item, item_k, 0)\n","    self.mlp = nn.Sequential(\n","        nn.Linear(user_k+item_k+num_genres, hidden_dim),\n","        nn.ReLU(),\n","        nn.BatchNorm1d(hidden_dim),\n","        nn.Linear(hidden_dim, hidden_dim),\n","        nn.ReLU(),\n","        nn.BatchNorm1d(hidden_dim),\n","        nn.Linear(hidden_dim, 1)\n","    )\n","  def forward(self, x, g):\n","    user_feature = self.user_emb(x[:,0]) # (batch_size, user_k)\n","    item_feature = self.item_emb(x[:,1]) # (batch_size, item_k)\n","    out = torch.cat([user_feature, item_feature, g], 1)\n","    out = self.mlp(out)\n","    out = torch.sigmoid(out) * 5\n","    return out.squeeze()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7kyXePyF-j2","colab_type":"code","colab":{}},"source":["# 평가함수 작성\n","\n","def eval_net(net, loader, score_fn=nn.functional.l1_loss, device='cpu'):\n","  ys = []\n","  y_preds = []\n","  for x, y, g in loader:\n","    x = x.to(device)\n","    g = g.to(device)\n","    ys.append(y)\n","    with torch.no_grad():\n","      y_pred = net(x, g).cpu()\n","    y_preds.append(y_pred)\n","  score = score_fn(torch.cat(ys).squeeze(), torch.cat(y_preds))\n","  return score.item()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gA21GiWeGRB7","colab_type":"code","colab":{}},"source":["# 훈련 부분 작성하기\n","from statistics import mean\n","\n","def train_net(net, loss_fn, optimizer, loader, device='cpu'):\n","  losses = []\n","  for x, y, g in loader:\n","    x = x.to(device)\n","    y = y.to(device)\n","    g = g.to(device)\n","    out = net(x, g)\n","    loss = loss_fn(out, y)\n","    net.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    losses.append(loss.item())\n","  return mean(losses)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKqf7UoDGpDz","colab_type":"code","outputId":"59ae0a8a-7ff6-4d48-c713-a7a4eac4e96b","executionInfo":{"status":"ok","timestamp":1568090798891,"user_tz":-540,"elapsed":1291353,"user":{"displayName":"김호현","photoUrl":"","userId":"14192226292936313885"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["# 훈련하기\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","max_user, max_item = data.max(0)\n","max_user = int(max_user) + 1\n","max_item = int(max_item) + 1\n","\n","net = NeuralMatrixFactorization2(max_user, max_item, num_genres)\n","net.cuda()\n","optimizer = optim.Adam(net.parameters(), lr=0.01)\n","loss_fn = nn.MSELoss()\n","\n","for epoch in range(3):\n","  \n","  net.train()\n","  loss = train_net(net, loss_fn, optimizer, train_loader1, device=device)\n","  net.eval()\n","  test_score = eval_net(net, test_loader, device=device)\n","  print(epoch, loss, test_score)\n","  \n","  net.train()\n","  loss = train_net(net, loss_fn, optimizer, train_loader2, device=device)\n","  net.eval()\n","  test_score = eval_net(net, test_loader, device=device)\n","  print(epoch, loss, test_score)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["0 0.7842741769735316 0.6532257795333862\n","0 0.716683269774412 0.6464508771896362\n","1 0.6908000394617195 0.633633553981781\n","1 0.672769879745542 0.6257384419441223\n","2 0.6563715703590467 0.6199726462364197\n","2 0.6422819652248162 0.6206002831459045\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TgvKz7HKB12k","colab_type":"text"},"source":["장르 정보까지 이용하자 손실이 조금 더 낮아진 걸 확인할 수 있습니다."]}]}