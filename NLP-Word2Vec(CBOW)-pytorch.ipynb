{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "CBOW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK85zKGI6KcX",
        "colab_type": "text"
      },
      "source": [
        "# CBOW\n",
        "\n",
        "Word2Vec 모델 중 하나인 **CBOW**(continuous bag-of-words)를 파이토치로 구현합니다. 《밑바닥부터 시작하는 딥러닝 2》을 참고했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkvbmA2dUgu0",
        "colab_type": "text"
      },
      "source": [
        "## PTB 데이터 불러오기\n",
        "\n",
        "**펜 트리뱅크**(Penn Treebank, PTB) 데이터셋. word2vec 발명자인 토마스 미콜로프(Tomas Mikolov) 웹 페이지에서 받을 수 있습니다. 원래의 PTB 문장에 몇 가지 전처리가 되어있습니다. 희소한 단어는 `<unk>`로 치환되어 있다던가, 구체적인 숫자는 `N`으로 대체되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NggcSlSH6KcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if 'ptb.train.txt' in os.listdir():\n",
        "    with open(\"ptb.train.txt\", 'r') as f:\n",
        "        text = f.read()        \n",
        "else:\n",
        "    from urllib.request import urlopen\n",
        "    url = 'https://raw.githubusercontent.com/tomsercu/lstm/master/data/ptb.train.txt'\n",
        "    html = urlopen(url)\n",
        "    text = html.read().decode()\n",
        "\n",
        "    with open(\"ptb.train.txt\", 'w') as f:\n",
        "        f.write(text)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyHnnAv66Kce",
        "colab_type": "text"
      },
      "source": [
        "## 훈련셋 만들기\n",
        "\n",
        "윈도우 내의 단어로 가운데 단어를 추론합니다. 여기서의 함수는 skip-gram 모델에서도 사용할 수 있습니다. skip-gram에서는 단순히 맥락과 타깃을 바꿔주기만 하면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA9Tu0GDZsS_",
        "colab_type": "text"
      },
      "source": [
        "### 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhfQWvJt6Kci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 전처리\n",
        "def preprocess(text):\n",
        "    \n",
        "    words = text.replace('\\n', '<eos>').strip().split()\n",
        "    word_to_id = {}\n",
        "    id_to_word = {}\n",
        "    for word in words:\n",
        "        if word not in word_to_id:\n",
        "            new_id = len(word_to_id)\n",
        "            word_to_id[word] = new_id\n",
        "            id_to_word[new_id] = word\n",
        "    \n",
        "    corpus = np.array([word_to_id[w] for w in words])\n",
        "    \n",
        "    return corpus, word_to_id, id_to_word\n",
        "\n",
        "# 훈련셋 만들기\n",
        "def create_contexts_target(corpus, window_size=1):\n",
        "    target = corpus[window_size:-window_size]\n",
        "    contexts = []\n",
        "    \n",
        "    for idx in range(window_size, len(corpus)-window_size):\n",
        "        cs = []\n",
        "        for t in range(-window_size, window_size+1):\n",
        "            if t == 0:\n",
        "                continue\n",
        "            cs.append(corpus[idx+t])\n",
        "        contexts.append(cs)\n",
        "        \n",
        "    return np.array(contexts), np.array(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWCkxZNfZpW1",
        "colab_type": "text"
      },
      "source": [
        "### 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqvfkMfPZrV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window_size = 5\n",
        "\n",
        "# 훈련셋 만들기\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "contexts, target = create_contexts_target(corpus, window_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJv6I5daWEng",
        "colab_type": "text"
      },
      "source": [
        "## CBOW, 훈련 모델 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAJSHL6W6Kcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim \n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "# 모델을 훈련할 때 사용할 클래스\n",
        "class Trainer():\n",
        "    def __init__(self, model, optimizer):\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.model = model.to(self.device)\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_list = []\n",
        "        self.eval_interval = None        \n",
        "        self.current_epoch = 0\n",
        "\n",
        "    def fit(self, x, y, max_epoch=10, batch_size=32, verbose=True):\n",
        "        x = torch.tensor(x)\n",
        "        y = torch.tensor(y)\n",
        "        dataset = TensorDataset(x, y)\n",
        "        loader = DataLoader(dataset, batch_size, shuffle=True, drop_last=True)\n",
        "        max_iters = len(loader)\n",
        "\n",
        "        total_loss = 0\n",
        "        start_time = time.time()\n",
        "        for epoch in range(max_epoch):\n",
        "            running_loss = 0\n",
        "            for iters, (xx, yy) in enumerate(loader):\n",
        "                xx = xx.to(self.device)\n",
        "                yy = yy.to(self.device)\n",
        "                loss = self.model(xx, yy, self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "            self.current_epoch += 1\n",
        "\n",
        "            # 평가\n",
        "            if verbose:\n",
        "                avg_loss = total_loss / max_iters\n",
        "                elapsed_time = time.time() - start_time\n",
        "                print('| 에폭 %d |  반복 %d / %d | 시간 %d[s] | 손실 %.3f'\n",
        "                        % (self.current_epoch, iters + 1, max_iters, elapsed_time, avg_loss))\n",
        "                self.loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "\n",
        "    def plot(self):\n",
        "        x = np.arange(len(self.loss_list))\n",
        "        plt.plot(x, self.loss_list, label='train')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('loss')\n",
        "        plt.show()\n",
        "\n",
        "# 네거티브 샘플링을 위한 클래스\n",
        "class UnigramSampler():\n",
        "    def __init__(self, corpus, power=0.75, sample_size=5):\n",
        "        self.sample_size = sample_size\n",
        "        corpus = torch.tensor(corpus)\n",
        "        self.weight = torch.bincount(corpus).float() ** power\n",
        "    \n",
        "    def get_negative_sample(self, y):\n",
        "        # 부정적 예에 타깃이 포함될 수 있다.\n",
        "        # 계산량과 구현상 편의를 위해 아래와 같이 구현\n",
        "        n_samples = torch.multinomial(self.weight, y.nelement()*self.sample_size, replacement=True)\n",
        "        n_samples = n_samples.view(len(y), -1)\n",
        "        return n_samples\n",
        "\n",
        "# CBOW 모델\n",
        "class CBOW(nn.Module):\n",
        "    def __init__(self, corpus, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        V = len(np.unique(corpus))\n",
        "        H = hidden_size\n",
        "        \n",
        "        # 계층 생성\n",
        "        self.sampler = UnigramSampler(corpus)\n",
        "        self.emb1 = nn.Embedding(V, H)\n",
        "        self.emb2 = nn.Embedding(V, H)\n",
        "        nn.init.normal_(self.emb1.weight, 0, 0.01)\n",
        "        nn.init.normal_(self.emb2.weight, 0, 0.01)\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss(reduction='sum')\n",
        "        \n",
        "        \n",
        "    def forward(self, x, y, device='cpu'):\n",
        "\n",
        "        h = self.emb1(x) # batch size, context size, embedding dim\n",
        "        h = h.mean(1)    # batch size, embedding dim\n",
        "        \n",
        "        # 긍정\n",
        "        target_W = self.emb2(y)                               # batch size, embedding dim\n",
        "        p_scores = torch.sum(h * target_W, 1)                 # batch size\n",
        "        p_loss = self.loss_fn(p_scores, torch.ones(p_scores.shape, device=device))\n",
        "\n",
        "        # 부정\n",
        "        n_samples = self.sampler.get_negative_sample(y).to(device)       # batch size, negative sample size\n",
        "        target_W = self.emb2(n_samples)                       # batch size, negative sample size, embedding dim\n",
        "        n_scores = torch.sum(h * target_W.transpose(0, 1), 2) # negative sample size, batch size\n",
        "        n_loss = self.loss_fn(n_scores, torch.zeros(n_scores.shape, device=device))\n",
        "        \n",
        "        # 평균 손실\n",
        "        loss = (n_loss + p_loss) / (p_scores.nelement() + n_scores.nelement())\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    def word_vecs(self):\n",
        "        return self.emb1.weight.data.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A5-73kCZhjH",
        "colab_type": "text"
      },
      "source": [
        "### 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i2A5IOI-HYN",
        "colab_type": "code",
        "outputId": "dbb25245-f7c6-4972-db05-b05202560141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "hidden_size = 100\n",
        "batch_size = 128\n",
        "max_epoch = 15\n",
        "verbose = True\n",
        "\n",
        "# 모델 생성\n",
        "model = CBOW(corpus, hidden_size)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "trainer = Trainer(model, optimizer)\n",
        "trainer.fit(contexts, target, max_epoch, batch_size, verbose)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 에폭 1 |  반복 7262 / 7262 | 시간 35[s] | 손실 0.410\n",
            "| 에폭 2 |  반복 7262 / 7262 | 시간 70[s] | 손실 0.356\n",
            "| 에폭 3 |  반복 7262 / 7262 | 시간 105[s] | 손실 0.328\n",
            "| 에폭 4 |  반복 7262 / 7262 | 시간 141[s] | 손실 0.310\n",
            "| 에폭 5 |  반복 7262 / 7262 | 시간 176[s] | 손실 0.296\n",
            "| 에폭 6 |  반복 7262 / 7262 | 시간 212[s] | 손실 0.284\n",
            "| 에폭 7 |  반복 7262 / 7262 | 시간 247[s] | 손실 0.274\n",
            "| 에폭 8 |  반복 7262 / 7262 | 시간 283[s] | 손실 0.265\n",
            "| 에폭 9 |  반복 7262 / 7262 | 시간 318[s] | 손실 0.257\n",
            "| 에폭 10 |  반복 7262 / 7262 | 시간 353[s] | 손실 0.250\n",
            "| 에폭 11 |  반복 7262 / 7262 | 시간 389[s] | 손실 0.243\n",
            "| 에폭 12 |  반복 7262 / 7262 | 시간 424[s] | 손실 0.237\n",
            "| 에폭 13 |  반복 7262 / 7262 | 시간 459[s] | 손실 0.232\n",
            "| 에폭 14 |  반복 7262 / 7262 | 시간 494[s] | 손실 0.227\n",
            "| 에폭 15 |  반복 7262 / 7262 | 시간 530[s] | 손실 0.223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHL4vfsgSn-4",
        "colab_type": "code",
        "outputId": "f75b439d-ba4c-4a56-abb9-25b5a60ec5c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "trainer.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORyvD0kkZLVV",
        "colab_type": "text"
      },
      "source": [
        "## 평가\n",
        "\n",
        "특정 단어를 넣었을 때 유사한 단어를 가려낼 수 있는지, 그리고 단어 간 비유적 관계를 찾아낼 수 있는지를 볼 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXGnuqwoZbRt",
        "colab_type": "text"
      },
      "source": [
        "### 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7loUsSyZPIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def most_similar(query, word_to_id, id_to_word, similarity_matirx, top=5):\n",
        "    if query not in word_to_id:\n",
        "        print('%s(을)를 찾을 수 없습니다.' % query)\n",
        "        return\n",
        "    \n",
        "    print('\\n[query] ' + query)\n",
        "    query_id = word_to_id[query]\n",
        "    similarity = similarity_matirx[query_id]\n",
        "    \n",
        "    # 코사인 유사도 기준으로 내림차순으로 출력\n",
        "    count = 0\n",
        "    for i in (-1 * similarity).argsort():\n",
        "        if id_to_word[i] == query:\n",
        "            continue\n",
        "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
        "        \n",
        "        count += 1\n",
        "        if count >= top:\n",
        "            return\n",
        "\n",
        "def analogy(a, b, c, word_to_id, id_to_word, word_vecs, top=5):\n",
        "    for word in (a, b, c):\n",
        "        if word not in word_to_id:\n",
        "            print('%s(을)를 찾을 수 없습니다.' % word)\n",
        "            return\n",
        "\n",
        "    print('\\n[analogy] ' + a + ':' + b + ' = ' + c + ':?')\n",
        "    a_vec, b_vec, c_vec = word_vecs[word_to_id[a]], word_vecs[word_to_id[b]], word_vecs[word_to_id[c]]\n",
        "    query_vec = b_vec - a_vec + c_vec\n",
        "    word_vecs_norm = word_vecs / np.linalg.norm(word_vecs, axis=1, keepdims=True)\n",
        "    similarity = np.dot(word_vecs_norm, query_vec)\n",
        "\n",
        "    count = 0\n",
        "    for i in (-1 * similarity).argsort():\n",
        "        if id_to_word[i] in (a, b, c):\n",
        "            continue\n",
        "        print(' {0}: {1}'.format(id_to_word[i], similarity[i]))\n",
        "\n",
        "        count += 1\n",
        "        if count >= top:\n",
        "            return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGN5fA9XZePB",
        "colab_type": "text"
      },
      "source": [
        "### 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YrDoSagVugY",
        "colab_type": "code",
        "outputId": "62232736-91bf-4b6f-b204-b75a86a44c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "word_vecs = model.word_vecs()\n",
        "similarity_matirx = cosine_similarity(word_vecs)\n",
        "\n",
        "querys = ['you', 'year', 'car', 'toyota']\n",
        "for query in querys:\n",
        "    most_similar(query, word_to_id, id_to_word, similarity_matirx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[query] you\n",
            " we: 0.65359443\n",
            " i: 0.649264\n",
            " your: 0.58959234\n",
            " they: 0.58778715\n",
            " weird: 0.53438616\n",
            "\n",
            "[query] year\n",
            " month: 0.8382436\n",
            " week: 0.7372195\n",
            " spring: 0.73113346\n",
            " summer: 0.7276939\n",
            " decade: 0.6937586\n",
            "\n",
            "[query] car\n",
            " auto: 0.5592951\n",
            " cars: 0.5575627\n",
            " luxury: 0.5514948\n",
            " truck: 0.54987234\n",
            " window: 0.5421118\n",
            "\n",
            "[query] toyota\n",
            " seita: 0.604759\n",
            " nec: 0.5632381\n",
            " cars: 0.5625669\n",
            " beretta: 0.5597588\n",
            " coated: 0.5569509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LFD5yBO1btq",
        "colab_type": "code",
        "outputId": "69cbae86-c381-4735-ea5e-c36c1f23f4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "analogy('king', 'man', 'queen',  word_to_id, id_to_word, word_vecs)\n",
        "analogy('take', 'took', 'go',  word_to_id, id_to_word, word_vecs)\n",
        "analogy('car', 'cars', 'child',  word_to_id, id_to_word, word_vecs)\n",
        "analogy('good', 'better', 'bad',  word_to_id, id_to_word, word_vecs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[analogy] king:man = queen:?\n",
            " yard: 6.272502899169922\n",
            " minute: 6.164089202880859\n",
            " deliberations: 6.139381408691406\n",
            " dark: 5.99154806137085\n",
            " ducks: 5.938501358032227\n",
            "\n",
            "[analogy] take:took = go:?\n",
            " went: 5.663961887359619\n",
            " came: 5.450709342956543\n",
            " walked: 5.122747421264648\n",
            " ran: 5.119802474975586\n",
            " started: 4.906400680541992\n",
            "\n",
            "[analogy] car:cars = child:?\n",
            " children: 7.134904861450195\n",
            " parents: 6.776798248291016\n",
            " adults: 6.491278648376465\n",
            " patients: 6.327136039733887\n",
            " symptoms: 6.236928462982178\n",
            "\n",
            "[analogy] good:better = bad:?\n",
            " less: 4.6722283363342285\n",
            " greater: 4.582182884216309\n",
            " more: 4.517031669616699\n",
            " rather: 4.161499977111816\n",
            " worse: 4.156607627868652\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}